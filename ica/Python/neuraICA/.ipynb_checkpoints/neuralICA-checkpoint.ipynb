{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "import tensorflow as  tf\n",
    "\n",
    "import scipy.io as scio\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_standard(x):\n",
    "    return np.exp(-0.5*np.square(x))/(np.sqrt(2*np.pi))\n",
    "\n",
    "def scale(X,center=True,scale=True):\n",
    "    if(center==True):\n",
    "        X =X -np.mean(X,axis=0)\n",
    "    if(scale==True):\n",
    "        X =X/np.std(X,axis=0)\n",
    "    return X\n",
    "    \n",
    "def whiten(X):\n",
    "    [N,p] =X.shape\n",
    "    cov =(X.T@X)/N\n",
    "    [eig_vals,eig_vecs] =np.linalg.eig(cov)\n",
    "    P =(np.diag(1.0/np.sqrt(eig_vals)))@eig_vecs.T\n",
    "    return [P,(P@X.T).T]\n",
    "\n",
    "def group(y,B=500):\n",
    "    N =y.shape[0]\n",
    "    y =np.sort(y)\n",
    "    y_min =y[0]\n",
    "    y_max =y[-1]\n",
    "    freqs =np.zeros((B,),dtype=float)\n",
    "    ys    =np.zeros((B,),dtype=float)\n",
    "    gaps =(y_max-y_min)/(B-1)\n",
    "    left =y_min -0.5*gaps\n",
    "    ys =y_min+gaps*np.arange(B)\n",
    "    index =0\n",
    "    for i in range(N):\n",
    "        index =int(np.floor((y[i]-left)/gaps))\n",
    "        freqs[index] = freqs[index]+1.0\n",
    "    freqs =freqs/gaps\n",
    "    return [ys,freqs]\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "def Amari_metric(A0,A):\n",
    "    R =np.abs(A0@np.linalg.inv(A))\n",
    "    m =A0.shape[0]\n",
    "    row_max =np.max(R,axis=1)\n",
    "    col_max =np.max(R,axis=0)\n",
    "    return -1.0+(np.sum(np.sum(R,axis=1)/row_max)+np.sum(np.sum(R,axis=0)/col_max))/(2*m)\n",
    "    \n",
    "def mixmat(m):\n",
    "    A =np.random.normal(size=(m,m))\n",
    "    [u,s,vh] =np.linalg.svd(A,full_matrices=True)\n",
    "    d =np.sort(np.random.uniform(low=0.0,high=1.0,size=(m,)))+1.0\n",
    "    print('condition ',d[-1]/d[0])\n",
    "    A =u@vh.T@np.diag(d)\n",
    "    return A\n",
    "\n",
    "def orth(W):\n",
    "    [u,s,vh] =np.linalg.svd(W,full_matrices=True)\n",
    "    W =u@vh\n",
    "    return W\n",
    "\n",
    "\n",
    "def mdi_loss(y_true,y_pred):\n",
    "    #怎么不是在最小化，而是在增大\n",
    "    norm_val =K.exp(y_pred)*y_true\n",
    "    #return (K.log(K.mean(norm_val,axis=-1))-(K.mean(norm_val*y_pred,axis=-1)/K.mean(norm_val,axis=-1)))\n",
    "    return ((K.log(K.mean(norm_val,axis=-1))-(K.mean(y_pred,axis=-1)/(K.mean(norm_val,axis=-1)+K.epsilon()))))\n",
    "def mdi_loss2(y_true,y_pred):\n",
    "    norm_val =K.exp(y_pred)*y_true\n",
    "    return K.mean(norm_val,axis=-1)-K.mean(y_pred,axis=-1)\n",
    "\n",
    "\n",
    "def mdi_loss3(y_true,y_pred):\n",
    "    norm_val =K.exp(y_pred)*y_true\n",
    "    return K.mean(norm_val,axis=-1)*K.log(K.mean(norm_val,axis=-1))-K.mean(y_pred,axis=-1)\n",
    "\n",
    "def mdi_loss4(y_true,y_pred):\n",
    "    #很快收敛但是十分不稳定。\n",
    "    return K.mean(K.exp(y_pred),axis=-1)-K.mean(y_true*y_pred,axis=-1)\n",
    "\n",
    "def mdi_loss5(y_true,y_pred):\n",
    "    #很快收敛但是十分不稳定。\n",
    "    return K.sum(y_pred,axis=-1)-K.sum(y_true*K.log(y_pred),axis=-1)\n",
    "\n",
    "def negentropy(y_true,y_pred):\n",
    "    return K.mean(y_pred,axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"./data/dists.mat\"\n",
    "data = scio.loadmat(path)[\"dists\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S shape  (1024, 2)\n",
      "condition  1.59117998498\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa7684a2d30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa76560d710>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m  =2\n",
    "S  =data[[11,7],[3,4],:].T\n",
    "#s1 =np.random.binomial(100,0.33,1024)[:,np.newaxis]\n",
    "#s2 =np.random.binomial(250,0.55,1024)[:,np.newaxis]\n",
    "#S =np.c_[s1,s2]\n",
    "print('S shape ',S.shape)\n",
    "A0 =mixmat(2)\n",
    "#A0 =np.array([[0.4,0.6],[0.2,0.7]],dtype=float)\n",
    "X  =(A0@S.T).T\n",
    "\n",
    "plt.subplots(figsize=(12,6))\n",
    "for i in range(m):\n",
    "    plt.subplot(m,1,i+1)\n",
    "    plt.hist(S[:,i])\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(12,6))\n",
    "for i in range(m):\n",
    "    plt.subplot(m,1,i+1)\n",
    "    plt.hist(X[:,i])\n",
    "\n",
    "X  =scale(X,center=True,scale=False)\n",
    "[P,X] =whiten(X)\n",
    "target =np.linalg.inv(P@A0)\n",
    "W0 =np.random.normal(size=(2,2))\n",
    "W0 =orth(W0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_session = K.get_session()\n",
    "tf_session.run(tf.global_variables_initializer())\n",
    "y =K.variable([-0.5,2.0], dtype='float32', name=\"y\") \n",
    "w =K.variable(np.ones((1024)), dtype='float32', name=\"w\")\n",
    "print(\"y \",K.eval(y))\n",
    "print(\"w \",K.eval(w))\n",
    "res=-1.0*K.square(y)\n",
    "print(K.eval(K.gradients(res,[y])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralICA(X,W0,M=1024,maxiters=20,epochs=400,optimizer='rmsprop',tol=1e-7,activation='sigmoid',lbd=0.05):\n",
    "    [N,p] =X.shape\n",
    "    batch_size =N\n",
    "    m =p\n",
    "    models =[]\n",
    "    inputs =[]\n",
    "    outputs =[]\n",
    "    loss     =np.zeros((maxiters,m),dtype=float)\n",
    "    metrices =np.zeros((maxiters,m),dtype=float)\n",
    "    y_pred =np.zeros((N,m),dtype=float)\n",
    "    tol =1e-7\n",
    "    W=W0\n",
    "    W_last =np.ones(W0.shape,dtype=float)\n",
    "    for i in range(m):\n",
    "        input_tensor =Input(shape=(1,),dtype='float32')\n",
    "        x =layers.Dense(M,activation=activation,kernel_initializer='random_uniform',\n",
    "                bias_initializer='zeros')(input_tensor)\n",
    "        #x =layers.Dense(50,activation='sigmoid',kernel_initializer='random_uniform',\n",
    "        #            bias_initializer='zeros',kernel_regularizer=regularizers.l1(1))(x)\n",
    "        output_tensor =layers.Dense(1,activation=\"linear\",kernel_initializer='random_uniform',\n",
    "                bias_initializer='zeros',kernel_regularizer=regularizers.l2(lbd))(x)\n",
    "        model =Model(input_tensor,output_tensor)\n",
    "        model.compile(optimizer=optimizer,loss=mdi_loss2,metrics=[negentropy])\n",
    "        models.append(model)\n",
    "        inputs.append(input_tensor)\n",
    "        outputs.append(output_tensor)\n",
    "\n",
    "    for i in range(maxiters):\n",
    "        print('iteration ',i,' begin')\n",
    "        X_train =(W@X.T).T\n",
    "        y_train =gauss_standard(X_train)\n",
    "        #print('dist ',Amari_metric(W_last,W))\n",
    "        if(Amari_metric(W_last,W)<tol):\n",
    "            break\n",
    "        W_last =W.copy()\n",
    "        for j in range(m):\n",
    "            for k in range(epochs):\n",
    "                #print('epochs ',k)\n",
    "                [loss[i,j],metrices[i,j]] =models[j].train_on_batch(x=X_train[:,j],y=y_train[:,j])\n",
    "                #models[j].fit(X_train[:,j][:,np.newaxis],y_train[:,j][:,np.newaxis],epochs=100,batch_size=1024,verbose=0)\n",
    "                grad  =K.gradients(models[j].output,[models[j].input])[0]\n",
    "                grad2 =K.gradients(grad,[models[j].input])[0]\n",
    "                grads =K.function([models[j].input],[grad,grad2])\n",
    "                #print('grad ',grad)\n",
    "                #print('grad2 ',grad2)\n",
    "                #K.update(models[j].input,X_train[:,j])\n",
    "                [grad_val,grad2_val] =grads([X_train[:,j][:,np.newaxis]])\n",
    "        \n",
    "                #print('norm ',np.linalg.norm(grad_val))\n",
    "                #print('grad_val ',grad_val)\n",
    "                W[j,:] =np.mean(X*grad_val,axis=0)-np.mean(grad2_val)*W[j,:]\n",
    "                #if(j>0):\n",
    "                #      W[j,:] =W[j,:]-(np.sum(W[j,:]*W[j-1,:]))*W[j-1,:]\n",
    "                #W[j,:] =W[j,:]/np.linalg.norm(W[j,:])\n",
    "               #print('before W ',W)\n",
    "        W =orth(W)\n",
    "        #if(i<10):\n",
    "        #    print('W_last ',W_last)\n",
    "        #    print('W ',W )\n",
    "        #print('epoch ',i,' Amari metric: ',Amari_metric(target,W))\n",
    "        \n",
    "        print('iteration ',i,' loss ',loss[i,:],' negentropy ',metrices[i,:])\n",
    "    return [W,metrices]\n",
    "        \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss=mdi_loss,metrics=[negentropy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amari metric  0.737321831939\n",
      "dist  0.221303207104\n",
      "epoch  0  Amari metric:  0.198380926027\n",
      "loss  [-6195.67822266 -6345.71386719]\n",
      "metrices  [ 7.00031042  6.9094758 ]\n",
      "dist  0.470174533184\n",
      "epoch  1  Amari metric:  0.0733592926539\n",
      "loss  [-7073.26269531 -6224.31591797]\n",
      "metrices  [ 7.08972168  6.89564657]\n",
      "dist  0.123223397506\n",
      "epoch  2  Amari metric:  0.0970998724059\n",
      "loss  [-6875.85791016 -6203.97412109]\n",
      "metrices  [ 7.06377983  6.89479637]\n",
      "dist  0.0235714756338\n",
      "epoch  3  Amari metric:  0.0930767381047\n",
      "loss  [-6904.21777344 -6190.85693359]\n",
      "metrices  [ 7.06754065  6.89291143]\n",
      "dist  0.00398690750816\n",
      "epoch  4  Amari metric:  0.0931818942831\n",
      "loss  [-6889.96191406 -6189.34375   ]\n",
      "metrices  [ 7.06615067  6.89274311]\n",
      "dist  0.000104246915628\n",
      "epoch  5  Amari metric:  0.09371537376\n",
      "loss  [-6889.33496094 -6189.21484375]\n",
      "metrices  [ 7.06603527  6.89279366]\n",
      "dist  0.000528835433855\n",
      "epoch  6  Amari metric:  0.0928046156388\n",
      "loss  [-6892.16601562 -6191.6015625 ]\n",
      "metrices  [ 7.06640244  6.89311981]\n",
      "dist  0.000902861400615\n",
      "epoch  7  Amari metric:  0.0936557331275\n",
      "loss  [-6890.9609375  -6189.34863281]\n",
      "metrices  [ 7.06612968  6.89288759]\n",
      "dist  0.000843742505739\n",
      "epoch  8  Amari metric:  0.0924710840202\n",
      "loss  [-6892.453125   -6191.73144531]\n",
      "metrices  [ 7.06638193  6.8932128 ]\n",
      "dist  0.00117442037764\n",
      "epoch  9  Amari metric:  0.0934616094673\n",
      "loss  [-6891.61914062 -6190.42871094]\n",
      "metrices  [ 7.06602907  6.893116  ]\n",
      "dist  0.000981990312275\n",
      "epoch  10  Amari metric:  0.0920100747853\n",
      "loss  [-6889.15771484 -6190.70996094]\n",
      "metrices  [ 7.06607914  6.89314842]\n",
      "dist  0.00143908853206\n",
      "epoch  11  Amari metric:  0.0928281759122\n",
      "loss  [-6893.49121094 -6190.22265625]\n",
      "metrices  [ 7.06620598  6.89316416]\n",
      "dist  0.000811133150538\n",
      "epoch  12  Amari metric:  0.0913821667666\n",
      "loss  [-6891.59326172 -6189.28271484]\n",
      "metrices  [ 7.06611347  6.8930397 ]\n",
      "dist  0.0014337758759\n",
      "epoch  13  Amari metric:  0.0906651883485\n",
      "loss  [-6893.76953125 -6188.08691406]\n",
      "metrices  [ 7.06608963  6.89294624]\n",
      "dist  0.000711051950769\n",
      "epoch  14  Amari metric:  0.0906685574446\n",
      "loss  [-6891.19091797 -6189.55712891]\n",
      "metrices  [ 7.06580687  6.8931551 ]\n",
      "dist  3.34146162162e-06\n",
      "epoch  15  Amari metric:  0.0796079573459\n",
      "loss  [-6891.48486328 -6189.56054688]\n",
      "metrices  [ 7.06576586  6.89319277]\n",
      "dist  0.0109807822449\n",
      "epoch  16  Amari metric:  0.0911770799528\n",
      "loss  [-6876.08007812 -6198.265625  ]\n",
      "metrices  [ 7.06374264  6.89448547]\n",
      "dist  0.0114851740992\n",
      "epoch  17  Amari metric:  0.329757447191\n",
      "loss  [-6891.78027344 -6189.75683594]\n",
      "metrices  [ 7.06582594  6.89329672]\n",
      "dist  0.231610711892\n",
      "epoch  18  Amari metric:  0.0966189726847\n",
      "loss  [-6682.33447266 -6254.47802734]\n",
      "metrices  [ 7.04682827  6.8984766 ]\n",
      "dist  0.225934335003\n",
      "epoch  19  Amari metric:  0.14753025037\n",
      "loss  [-6904.42138672 -6191.52978516]\n",
      "metrices  [ 7.06738043  6.89358139]\n",
      "dist  0.0501936567818\n",
      "epoch  20  Amari metric:  0.159930373484\n",
      "loss  [-6991.2578125  -6187.79589844]\n",
      "metrices  [ 7.07871199  6.89251661]\n",
      "dist  0.0121138665071\n",
      "epoch  21  Amari metric:  0.176514558327\n",
      "loss  [-7027.03662109 -6198.59912109]\n",
      "metrices  [ 7.08294535  6.89381695]\n",
      "dist  0.0161283509114\n",
      "epoch  22  Amari metric:  0.192503934316\n",
      "loss  [-7085.26660156 -6206.04833984]\n",
      "metrices  [ 7.08855391  6.89449501]\n",
      "dist  0.0154634755271\n",
      "epoch  23  Amari metric:  0.206269417525\n",
      "loss  [-7121.60595703 -6215.27001953]\n",
      "metrices  [ 7.08947372  6.89539862]\n",
      "dist  0.0132394270104\n",
      "epoch  24  Amari metric:  0.213126768695\n",
      "loss  [-7076.80273438 -6231.01757812]\n",
      "metrices  [ 7.07778311  6.89715624]\n",
      "dist  0.00656843327751\n",
      "epoch  25  Amari metric:  0.214389157451\n",
      "loss  [-7057.09472656 -6226.66699219]\n",
      "metrices  [ 7.06857347  6.89635801]\n",
      "dist  0.00120720092994\n",
      "epoch  26  Amari metric:  0.212518775381\n",
      "loss  [-7053.46533203 -6228.42041016]\n",
      "metrices  [ 7.06231356  6.89621401]\n",
      "dist  0.00178883748308\n",
      "epoch  27  Amari metric:  0.208173952123\n",
      "loss  [-7061.57861328 -6231.94824219]\n",
      "metrices  [ 7.0614934   6.89623737]\n",
      "dist  0.00416065190997\n",
      "epoch  28  Amari metric:  0.204330396661\n",
      "loss  [-7071.06054688 -6235.45605469]\n",
      "metrices  [ 7.06246853  6.8961544 ]\n",
      "dist  0.00368664716488\n",
      "epoch  29  Amari metric:  0.201882084434\n",
      "loss  [-7086.16210938 -6229.38818359]\n",
      "metrices  [ 7.06378698  6.89519978]\n",
      "dist  0.0023512609517\n",
      "epoch  30  Amari metric:  0.200181619209\n",
      "loss  [-7099.75244141 -6226.75537109]\n",
      "metrices  [ 7.06441021  6.89483023]\n",
      "dist  0.00163437262269\n",
      "epoch  31  Amari metric:  0.198363015803\n",
      "loss  [-7102.56835938 -6226.16015625]\n",
      "metrices  [ 7.06481075  6.89474726]\n",
      "dist  0.00174910274869\n",
      "epoch  32  Amari metric:  0.196951250759\n",
      "loss  [-7108.45263672 -6226.99707031]\n",
      "metrices  [ 7.0650754   6.89492655]\n",
      "dist  0.00135864922426\n",
      "epoch  33  Amari metric:  0.195888639072\n",
      "loss  [-7120.99755859 -6221.8359375 ]\n",
      "metrices  [ 7.06607533  6.89413834]\n",
      "dist  0.00102311189235\n",
      "epoch  34  Amari metric:  0.194488960106\n",
      "loss  [-7120.06445312 -6220.28857422]\n",
      "metrices  [ 7.06578112  6.89379072]\n",
      "dist  0.00134827540068\n",
      "epoch  35  Amari metric:  0.193185595978\n",
      "loss  [-7121.86181641 -6218.66796875]\n",
      "metrices  [ 7.065938    6.89343262]\n",
      "dist  0.00125613352504\n",
      "epoch  36  Amari metric:  0.192125520196\n",
      "loss  [-7126.88525391 -6220.73583984]\n",
      "metrices  [ 7.06604958  6.89374208]\n",
      "dist  0.00102211085784\n",
      "epoch  37  Amari metric:  0.191097464052\n",
      "loss  [-7131.41796875 -6219.046875  ]\n",
      "metrices  [ 7.06620884  6.89353991]\n",
      "dist  0.000991621320964\n",
      "epoch  38  Amari metric:  0.189957387343\n",
      "loss  [-7131.17333984 -6219.57568359]\n",
      "metrices  [ 7.0657053   6.89344931]\n",
      "dist  0.00110011123271\n",
      "epoch  39  Amari metric:  0.188743381025\n",
      "loss  [-7128.87792969 -6218.42480469]\n",
      "metrices  [ 7.06487989  6.89309978]\n",
      "dist  0.00117195465786\n",
      "epoch  40  Amari metric:  0.187612483809\n",
      "loss  [-7130.60009766 -6213.47265625]\n",
      "metrices  [ 7.06445074  6.89226532]\n",
      "dist  0.0010921907379\n",
      "epoch  41  Amari metric:  0.186674521644\n",
      "loss  [-7137.48583984 -6212.61181641]\n",
      "metrices  [ 7.06430674  6.89199781]\n",
      "dist  0.000906198659104\n",
      "epoch  42  Amari metric:  0.185456002319\n",
      "loss  [-7136.63330078 -6214.87060547]\n",
      "metrices  [ 7.06401873  6.89218998]\n",
      "dist  0.00117771271481\n",
      "epoch  43  Amari metric:  0.184236334155\n",
      "loss  [-7132.93066406 -6216.07617188]\n",
      "metrices  [ 7.06312799  6.89226246]\n",
      "dist  0.00117933820428\n",
      "epoch  44  Amari metric:  0.182763115272\n",
      "loss  [-7128.35107422 -6212.19335938]\n",
      "metrices  [ 7.06237841  6.89174843]\n",
      "dist  0.00142518823847\n",
      "epoch  45  Amari metric:  0.181363109377\n",
      "loss  [-7126.96484375 -6213.23632812]\n",
      "metrices  [ 7.06240702  6.89184332]\n",
      "dist  0.00135505015137\n",
      "epoch  46  Amari metric:  0.180056077948\n",
      "loss  [-7122.63916016 -6211.05712891]\n",
      "metrices  [ 7.06187201  6.89168835]\n",
      "dist  0.00126566228626\n",
      "epoch  47  Amari metric:  0.178840666224\n",
      "loss  [-7119.55126953 -6210.79785156]\n",
      "metrices  [ 7.06078815  6.89178276]\n",
      "dist  0.00117746001068\n",
      "epoch  48  Amari metric:  0.177235457658\n",
      "loss  [-7110.32421875 -6210.87695312]\n",
      "metrices  [ 7.06003475  6.89172029]\n",
      "dist  0.00155584517511\n",
      "epoch  49  Amari metric:  0.175918618456\n",
      "loss  [-7106.15625    -6211.34716797]\n",
      "metrices  [ 7.05981255  6.89164352]\n",
      "dist  0.00127698437234\n",
      "epoch  50  Amari metric:  0.174783215673\n",
      "loss  [-7102.01953125 -6211.76513672]\n",
      "metrices  [ 7.05931664  6.89142084]\n",
      "dist  0.00110149974722\n",
      "epoch  51  Amari metric:  0.173616167307\n",
      "loss  [-7095.69189453 -6211.15478516]\n",
      "metrices  [ 7.05844641  6.89111805]\n",
      "dist  0.00113264233042\n",
      "epoch  52  Amari metric:  0.172698321689\n",
      "loss  [-7096.25537109 -6210.24560547]\n",
      "metrices  [ 7.05826521  6.89064026]\n",
      "dist  0.000891099242645\n",
      "epoch  53  Amari metric:  0.171537710838\n",
      "loss  [-7089.5546875  -6210.52685547]\n",
      "metrices  [ 7.05779457  6.89027929]\n",
      "dist  0.00112718277259\n",
      "epoch  54  Amari metric:  0.170770261433\n",
      "loss  [-7090.83398438 -6211.87304688]\n",
      "metrices  [ 7.05766487  6.89016771]\n",
      "dist  0.000745584561356\n",
      "epoch  55  Amari metric:  0.170127490786\n",
      "loss  [-7094.40136719 -6210.66552734]\n",
      "metrices  [ 7.05758142  6.88967037]\n",
      "dist  0.000624603978634\n",
      "epoch  56  Amari metric:  0.169410860345\n",
      "loss  [-7094.86572266 -6209.74023438]\n",
      "metrices  [ 7.05731487  6.8891778 ]\n",
      "dist  0.00069653270741\n",
      "epoch  57  Amari metric:  0.168131826087\n",
      "loss  [-7081.13427734 -6209.08007812]\n",
      "metrices  [ 7.05625582  6.88870716]\n",
      "dist  0.00124357243115\n",
      "epoch  58  Amari metric:  0.166830728485\n",
      "loss  [-7067.51074219 -6205.83544922]\n",
      "metrices  [ 7.05550861  6.8879652 ]\n",
      "dist  0.00126555750562\n",
      "epoch  59  Amari metric:  0.166284150228\n",
      "loss  [-7070.67724609 -6207.84472656]\n",
      "metrices  [ 7.05566406  6.88796616]\n",
      "dist  0.000531807564965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  60  Amari metric:  0.165824288867\n",
      "loss  [-7073.40185547 -6205.96337891]\n",
      "metrices  [ 7.05577707  6.88741541]\n",
      "dist  0.000447506921349\n",
      "epoch  61  Amari metric:  0.165005085247\n",
      "loss  [-7066.05371094 -6206.5       ]\n",
      "metrices  [ 7.05529881  6.88715363]\n",
      "dist  0.000797359717177\n",
      "epoch  62  Amari metric:  0.164540995572\n",
      "loss  [-7068.13525391 -6206.76464844]\n",
      "metrices  [ 7.05492544  6.88690233]\n",
      "dist  0.000451807875296\n",
      "epoch  63  Amari metric:  0.16397162787\n",
      "loss  [-7070.02246094 -6209.18896484]\n",
      "metrices  [ 7.05488491  6.8870244 ]\n",
      "dist  0.000554391512986\n",
      "epoch  64  Amari metric:  0.163374648742\n",
      "loss  [-7070.24560547 -6209.65136719]\n",
      "metrices  [ 7.05451965  6.88688707]\n",
      "dist  0.000581384864974\n",
      "epoch  65  Amari metric:  0.162581149116\n",
      "loss  [-7066.50439453 -6209.35107422]\n",
      "metrices  [ 7.05426311  6.88664961]\n",
      "dist  0.00077294275462\n",
      "epoch  66  Amari metric:  0.161893157366\n",
      "loss  [-7063.52050781 -6207.73779297]\n",
      "metrices  [ 7.05403519  6.88621664]\n",
      "dist  0.000670325398906\n",
      "epoch  67  Amari metric:  0.161178476867\n",
      "loss  [-7059.36328125 -6208.30761719]\n",
      "metrices  [ 7.05365515  6.88628864]\n",
      "dist  0.000696482827229\n",
      "epoch  68  Amari metric:  0.160672250378\n",
      "loss  [-7060.09228516 -6210.28808594]\n",
      "metrices  [ 7.05367184  6.88642168]\n",
      "dist  0.000493431178093\n",
      "epoch  69  Amari metric:  0.160133357479\n",
      "loss  [-7058.94824219 -6209.70556641]\n",
      "metrices  [ 7.05336428  6.88622904]\n",
      "dist  0.000525357847996\n",
      "epoch  70  Amari metric:  0.159377426415\n",
      "loss  [-7052.55322266 -6210.88671875]\n",
      "metrices  [ 7.05276966  6.88628721]\n",
      "dist  0.000737093691347\n",
      "epoch  71  Amari metric:  0.158970084837\n",
      "loss  [-7054.75       -6210.10058594]\n",
      "metrices  [ 7.05274248  6.8860774 ]\n",
      "dist  0.00039726262589\n",
      "epoch  72  Amari metric:  0.15835607627\n",
      "loss  [-7051.32275391 -6208.44091797]\n",
      "metrices  [ 7.052248    6.88580656]\n",
      "dist  0.000598910776343\n",
      "epoch  73  Amari metric:  0.157489288964\n",
      "loss  [-7041.57324219 -6207.73583984]\n",
      "metrices  [ 7.05178404  6.88559675]\n",
      "dist  0.000845667262924\n",
      "epoch  74  Amari metric:  0.157181226823\n",
      "loss  [-7044.57714844 -6208.31787109]\n",
      "metrices  [ 7.05201674  6.88565302]\n",
      "dist  0.000300610161372\n",
      "epoch  75  Amari metric:  0.156842583387\n",
      "loss  [-7044.43017578 -6206.73095703]\n",
      "metrices  [ 7.0519805   6.88546658]\n",
      "dist  0.00033048445968\n",
      "epoch  76  Amari metric:  0.156571948475\n",
      "loss  [-7045.45214844 -6205.34130859]\n",
      "metrices  [ 7.05199575  6.88529253]\n",
      "dist  0.000264139088541\n",
      "epoch  77  Amari metric:  0.156246817174\n",
      "loss  [-7045.35107422 -6207.11523438]\n",
      "metrices  [ 7.05186367  6.88556862]\n",
      "dist  0.000317356319901\n",
      "epoch  78  Amari metric:  0.155841674855\n",
      "loss  [-7042.92382812 -6206.89453125]\n",
      "metrices  [ 7.05158377  6.88550472]\n",
      "dist  0.000395498023622\n",
      "epoch  79  Amari metric:  0.15543846848\n",
      "loss  [-7041.13476562 -6207.47119141]\n",
      "metrices  [ 7.05142117  6.88559294]\n",
      "dist  0.000393656542265\n",
      "epoch  80  Amari metric:  0.155121644018\n",
      "loss  [-7040.52539062 -6206.46630859]\n",
      "metrices  [ 7.05122089  6.88553715]\n",
      "dist  0.000309354340605\n",
      "epoch  81  Amari metric:  0.154765600028\n",
      "loss  [-7039.51220703 -6206.94824219]\n",
      "metrices  [ 7.05101013  6.88566637]\n",
      "dist  0.000347684556214\n",
      "epoch  82  Amari metric:  0.154419956215\n",
      "loss  [-7038.36376953 -6206.90966797]\n",
      "metrices  [ 7.05095339  6.88579607]\n",
      "dist  0.000337564335547\n",
      "epoch  83  Amari metric:  0.154075270323\n",
      "loss  [-7036.46191406 -6207.28857422]\n",
      "metrices  [ 7.05087042  6.88598871]\n",
      "dist  0.00033666383128\n",
      "epoch  84  Amari metric:  0.153987001046\n",
      "loss  [-7040.58154297 -6206.62548828]\n",
      "metrices  [ 7.05101061  6.88608742]\n",
      "dist  8.62205524834e-05\n",
      "epoch  85  Amari metric:  0.153765414021\n",
      "loss  [-7041.04980469 -6207.28515625]\n",
      "metrices  [ 7.0509572   6.88636112]\n",
      "dist  0.000216454084175\n",
      "epoch  86  Amari metric:  0.153382504388\n",
      "loss  [-7037.5625     -6208.15722656]\n",
      "metrices  [ 7.05075216  6.88666725]\n",
      "dist  0.000374073685199\n",
      "epoch  87  Amari metric:  0.153103889095\n",
      "loss  [-7035.20947266 -6208.04248047]\n",
      "metrices  [ 7.05037737  6.88679028]\n",
      "dist  0.000272212985342\n",
      "epoch  88  Amari metric:  0.152938902363\n",
      "loss  [-7036.96533203 -6208.61669922]\n",
      "metrices  [ 7.05040836  6.88702965]\n",
      "dist  0.000161206186702\n",
      "epoch  89  Amari metric:  0.152769511275\n",
      "loss  [-7038.13427734 -6208.57373047]\n",
      "metrices  [ 7.05042124  6.88717604]\n",
      "dist  0.000165517885687\n",
      "epoch  90  Amari metric:  0.152607090501\n",
      "loss  [-7039.09765625 -6209.59033203]\n",
      "metrices  [ 7.05041409  6.8874588 ]\n",
      "dist  0.000158714807294\n",
      "epoch  91  Amari metric:  0.152309497568\n",
      "loss  [-7036.34130859 -6209.33984375]\n",
      "metrices  [ 7.05018663  6.88756895]\n",
      "dist  0.000290822669414\n",
      "epoch  92  Amari metric:  0.152172253059\n",
      "loss  [-7037.35253906 -6208.65136719]\n",
      "metrices  [ 7.0501523   6.88763666]\n",
      "dist  0.000134130860322\n",
      "epoch  93  Amari metric:  0.152014180404\n",
      "loss  [-7038.05810547 -6208.00048828]\n",
      "metrices  [ 7.05012798  6.88769197]\n",
      "dist  0.000154493261434\n",
      "epoch  94  Amari metric:  0.151819693481\n",
      "loss  [-7037.22460938 -6208.04980469]\n",
      "metrices  [ 7.04990292  6.88778305]\n",
      "dist  0.000190092914962\n",
      "epoch  95  Amari metric:  0.151668503831\n",
      "loss  [-7037.69091797 -6207.14355469]\n",
      "metrices  [ 7.04986191  6.88777637]\n",
      "dist  0.000147781425841\n",
      "epoch  96  Amari metric:  0.151553268605\n",
      "loss  [-7039.06640625 -6207.49609375]\n",
      "metrices  [ 7.04991293  6.88787889]\n",
      "dist  0.000112641956597\n",
      "epoch  97  Amari metric:  0.151438227361\n",
      "loss  [-7039.96289062 -6207.69775391]\n",
      "metrices  [ 7.04993153  6.88796282]\n",
      "dist  0.000112456174679\n",
      "epoch  98  Amari metric:  0.15107758067\n",
      "loss  [-7034.26953125 -6207.78320312]\n",
      "metrices  [ 7.04958439  6.88801289]\n",
      "dist  0.000352567477994\n",
      "epoch  99  Amari metric:  0.150938949835\n",
      "loss  [-7033.60839844 -6206.37597656]\n",
      "metrices  [ 7.04951334  6.88786936]\n",
      "dist  0.000135535212542\n",
      "epoch  100  Amari metric:  0.150703245942\n",
      "loss  [-7030.65087891 -6206.17285156]\n",
      "metrices  [ 7.04933739  6.88787317]\n",
      "dist  0.000230453352108\n",
      "epoch  101  Amari metric:  0.150572127215\n",
      "loss  [-7029.22070312 -6208.54101562]\n",
      "metrices  [ 7.04913187  6.88833714]\n",
      "dist  0.000128204851174\n",
      "epoch  102  Amari metric:  0.150470495073\n",
      "loss  [-7028.42822266 -6208.23046875]\n",
      "metrices  [ 7.04906845  6.88835144]\n",
      "dist  9.93769542903e-05\n",
      "epoch  103  Amari metric:  0.150400618195\n",
      "loss  [-7028.16650391 -6208.12011719]\n",
      "metrices  [ 7.04901457  6.88840437]\n",
      "dist  6.83280531404e-05\n",
      "epoch  104  Amari metric:  0.150391652902\n",
      "loss  [-7029.19384766 -6208.03417969]\n",
      "metrices  [ 7.04910946  6.88845062]\n",
      "dist  8.76667843452e-06\n",
      "epoch  105  Amari metric:  0.15035178819\n",
      "loss  [-7029.27636719 -6208.13623047]\n",
      "metrices  [ 7.04907703  6.8885293 ]\n",
      "dist  3.89818401798e-05\n",
      "epoch  106  Amari metric:  0.150330205017\n",
      "loss  [-7029.85595703 -6207.69824219]\n",
      "metrices  [ 7.04909182  6.88853884]\n",
      "dist  2.11053676082e-05\n",
      "epoch  107  Amari metric:  0.150287006227\n",
      "loss  [-7029.91259766 -6207.60693359]\n",
      "metrices  [ 7.04904699  6.88858175]\n",
      "dist  4.22428620885e-05\n",
      "epoch  108  Amari metric:  0.150254798055\n",
      "loss  [-7030.26025391 -6205.72412109]\n",
      "metrices  [ 7.0490303   6.88826942]\n",
      "dist  3.14958004761e-05\n",
      "epoch  109  Amari metric:  0.150198043304\n",
      "loss  [-7030.04492188 -6205.66796875]\n",
      "metrices  [ 7.04894209  6.88828564]\n",
      "dist  5.55001887332e-05\n",
      "epoch  110  Amari metric:  0.150168080791\n",
      "loss  [-7030.62304688 -6205.62255859]\n",
      "metrices  [ 7.04895258  6.88829708]\n",
      "dist  2.93005662639e-05\n",
      "epoch  111  Amari metric:  0.15013391864\n",
      "loss  [-7030.88623047 -6205.72070312]\n",
      "metrices  [ 7.0489316   6.88834381]\n",
      "dist  3.34077370183e-05\n",
      "epoch  112  Amari metric:  0.15005617858\n",
      "loss  [-7029.76269531 -6205.78027344]\n",
      "metrices  [ 7.04863214  6.88839579]\n",
      "dist  7.60245496636e-05\n",
      "epoch  113  Amari metric:  0.150023726737\n",
      "loss  [-7030.37646484 -6205.73095703]\n",
      "metrices  [ 7.04862261  6.88844347]\n",
      "dist  3.17362327076e-05\n",
      "epoch  114  Amari metric:  0.149989585606\n",
      "loss  [-7030.50292969 -6205.38427734]\n",
      "metrices  [ 7.04858303  6.88846302]\n",
      "dist  3.33885948782e-05\n",
      "epoch  115  Amari metric:  0.149967630854\n",
      "loss  [-7030.83203125 -6207.28808594]\n",
      "metrices  [ 7.04856348  6.88888884]\n",
      "dist  2.14710043267e-05\n",
      "epoch  116  Amari metric:  0.149939665847\n",
      "loss  [-7030.93115234 -6207.20166016]\n",
      "metrices  [ 7.04852533  6.88894844]\n",
      "dist  2.73490293359e-05\n",
      "epoch  117  Amari metric:  0.149891994879\n",
      "loss  [-7030.51416016 -6207.22265625]\n",
      "metrices  [ 7.04843855  6.88901997]\n",
      "dist  4.6621449445e-05\n",
      "epoch  118  Amari metric:  0.149835236755\n",
      "loss  [-7029.8125     -6207.46972656]\n",
      "metrices  [ 7.04830551  6.88913393]\n",
      "dist  5.55093934829e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  119  Amari metric:  0.149790893569\n",
      "loss  [-7029.31640625 -6205.75830078]\n",
      "metrices  [ 7.04821348  6.8889966 ]\n",
      "dist  4.33682377532e-05\n",
      "epoch  120  Amari metric:  0.149775380929\n",
      "loss  [-7029.51025391 -6205.63867188]\n",
      "metrices  [ 7.04818058  6.88905001]\n",
      "dist  1.51717051187e-05\n",
      "epoch  121  Amari metric:  0.14975917653\n",
      "loss  [-7029.68505859 -6205.96289062]\n",
      "metrices  [ 7.04815149  6.889184  ]\n",
      "dist  1.58483346726e-05\n",
      "epoch  122  Amari metric:  0.149743309701\n",
      "loss  [-7029.80566406 -6205.92138672]\n",
      "metrices  [ 7.04811621  6.88927269]\n",
      "dist  1.55182540631e-05\n",
      "epoch  123  Amari metric:  0.149711633048\n",
      "loss  [-7029.43603516 -6205.96875   ]\n",
      "metrices  [ 7.0480504   6.88937759]\n",
      "dist  3.09809728645e-05\n",
      "epoch  124  Amari metric:  0.149691169212\n",
      "loss  [-7029.47607422 -6206.02246094]\n",
      "metrices  [ 7.04801273  6.88949108]\n",
      "dist  2.00145638498e-05\n",
      "epoch  125  Amari metric:  0.149647435396\n",
      "loss  [-7028.77685547 -6206.17773438]\n",
      "metrices  [ 7.04792786  6.8896203 ]\n",
      "dist  4.27740648188e-05\n",
      "epoch  126  Amari metric:  0.149615783785\n",
      "loss  [-7028.51220703 -6206.61035156]\n",
      "metrices  [ 7.04779768  6.88978481]\n",
      "dist  3.09573488777e-05\n",
      "epoch  127  Amari metric:  0.149586792038\n",
      "loss  [-7028.25244141 -6206.62695312]\n",
      "metrices  [ 7.04773474  6.88991022]\n",
      "dist  2.83560790342e-05\n",
      "epoch  128  Amari metric:  0.149582482387\n",
      "loss  [-7028.65673828 -6206.65332031]\n",
      "metrices  [ 7.0477376   6.89004898]\n",
      "dist  4.21517905558e-06\n",
      "epoch  129  Amari metric:  0.149569039565\n",
      "loss  [-7028.69775391 -6206.69189453]\n",
      "metrices  [ 7.04769945  6.89019728]\n",
      "dist  1.31481747876e-05\n",
      "epoch  130  Amari metric:  0.149560428986\n",
      "loss  [-7028.81738281 -6206.47070312]\n",
      "metrices  [ 7.04766512  6.89030838]\n",
      "dist  8.42187505179e-06\n",
      "epoch  131  Amari metric:  0.149549012167\n",
      "loss  [-7028.89648438 -6206.49853516]\n",
      "metrices  [ 7.04762697  6.89045429]\n",
      "dist  1.11666473552e-05\n",
      "epoch  132  Amari metric:  0.149528761054\n",
      "loss  [-7028.80322266 -6206.65917969]\n",
      "metrices  [ 7.04755497  6.89061832]\n",
      "dist  1.9807452204e-05\n",
      "epoch  133  Amari metric:  0.149502101685\n",
      "loss  [-7028.67333984 -6206.83740234]\n",
      "metrices  [ 7.04748535  6.89079905]\n",
      "dist  2.6075495521e-05\n",
      "epoch  134  Amari metric:  0.149485590433\n",
      "loss  [-7028.85058594 -6206.89355469]\n",
      "metrices  [ 7.0474577  6.8909502]\n",
      "dist  1.61497362052e-05\n",
      "epoch  135  Amari metric:  0.149461909676\n",
      "loss  [-7028.87011719 -6206.94482422]\n",
      "metrices  [ 7.04741573  6.89110565]\n",
      "dist  2.31624005089e-05\n",
      "epoch  136  Amari metric:  0.149439730043\n",
      "loss  [-7029.04736328 -6207.05078125]\n",
      "metrices  [ 7.04739141  6.89125681]\n",
      "dist  2.16942799902e-05\n",
      "epoch  137  Amari metric:  0.149412027888\n",
      "loss  [-7029.25292969 -6206.44335938]\n",
      "metrices  [ 7.04737806  6.89132738]\n",
      "dist  2.70961517193e-05\n",
      "epoch  138  Amari metric:  0.149373041838\n",
      "loss  [-7029.06689453 -6206.51660156]\n",
      "metrices  [ 7.0472784   6.89147472]\n",
      "dist  3.81335748885e-05\n",
      "epoch  139  Amari metric:  0.149348110722\n",
      "loss  [-7029.11132812 -6206.7421875 ]\n",
      "metrices  [ 7.0472393   6.89165592]\n",
      "dist  2.43861958589e-05\n",
      "epoch  140  Amari metric:  0.149329832565\n",
      "loss  [-7029.46630859 -6207.29638672]\n",
      "metrices  [ 7.04724026  6.89188766]\n",
      "dist  1.7878763134e-05\n",
      "epoch  141  Amari metric:  0.149306127307\n",
      "loss  [-7029.62792969 -6207.43261719]\n",
      "metrices  [ 7.04721594  6.89203835]\n",
      "dist  2.31874203127e-05\n",
      "epoch  142  Amari metric:  0.149284986775\n",
      "loss  [-7029.79443359 -6207.09863281]\n",
      "metrices  [ 7.04718781  6.89212751]\n",
      "dist  2.06788548693e-05\n",
      "epoch  143  Amari metric:  0.14925710489\n",
      "loss  [-7029.89697266 -6206.97509766]\n",
      "metrices  [ 7.04715014  6.89224815]\n",
      "dist  2.72731831195e-05\n",
      "epoch  144  Amari metric:  0.149102408138\n",
      "loss  [-7025.94775391 -6207.02685547]\n",
      "metrices  [ 7.04691219  6.8923769 ]\n",
      "dist  0.000151323525771\n",
      "epoch  145  Amari metric:  0.149136127\n",
      "loss  [-7026.47119141 -6206.70556641]\n",
      "metrices  [ 7.04692888  6.8925252 ]\n",
      "dist  3.29841894857e-05\n",
      "epoch  146  Amari metric:  0.149136384221\n",
      "loss  [-7026.23535156 -6206.90332031]\n",
      "metrices  [ 7.04687643  6.89267111]\n",
      "dist  2.51615565272e-07\n",
      "epoch  147  Amari metric:  0.149147531755\n",
      "loss  [-7026.23632812 -6206.93115234]\n",
      "metrices  [ 7.04683971  6.89279413]\n",
      "dist  1.09045779964e-05\n",
      "epoch  148  Amari metric:  0.149152640959\n",
      "loss  [-7026.13818359 -6207.09179688]\n",
      "metrices  [ 7.04679537  6.89293575]\n",
      "dist  4.99783831898e-06\n",
      "epoch  149  Amari metric:  0.149161567662\n",
      "loss  [-7026.09765625 -6207.14941406]\n",
      "metrices  [ 7.04675436  6.89305878]\n",
      "dist  8.73211040253e-06\n",
      "epoch  150  Amari metric:  0.149176336751\n",
      "loss  [-7026.21582031 -6207.29736328]\n",
      "metrices  [ 7.0467267   6.89319515]\n",
      "dist  1.44470887613e-05\n",
      "epoch  151  Amari metric:  0.149192155302\n",
      "loss  [-7026.19726562 -6207.31933594]\n",
      "metrices  [ 7.04668856  6.89331245]\n",
      "dist  1.54736001761e-05\n",
      "epoch  152  Amari metric:  0.149204759239\n",
      "loss  [-7026.10107422 -6206.32763672]\n",
      "metrices  [ 7.04664803  6.89323521]\n",
      "dist  1.23290354672e-05\n",
      "epoch  153  Amari metric:  0.149232611577\n",
      "loss  [-7026.35644531 -6205.89550781]\n",
      "metrices  [ 7.04662704  6.89325237]\n",
      "dist  2.72446978271e-05\n",
      "epoch  154  Amari metric:  0.149252087923\n",
      "loss  [-7026.19433594 -6206.83496094]\n",
      "metrices  [ 7.04658031  6.893466  ]\n",
      "dist  1.90513079403e-05\n",
      "epoch  155  Amari metric:  0.149272218156\n",
      "loss  [-7026.02929688 -6206.87304688]\n",
      "metrices  [ 7.04652882  6.89356041]\n",
      "dist  1.96908112751e-05\n",
      "epoch  156  Amari metric:  0.149292058215\n",
      "loss  [-7025.85742188 -6207.35107422]\n",
      "metrices  [ 7.04647732  6.8937149 ]\n",
      "dist  1.94068587906e-05\n",
      "epoch  157  Amari metric:  0.149439138667\n",
      "loss  [-7029.96923828 -6207.17919922]\n",
      "metrices  [ 7.04665995  6.89377594]\n",
      "dist  0.000143865500384\n",
      "epoch  158  Amari metric:  0.149388497423\n",
      "loss  [-7029.33154297 -6207.04492188]\n",
      "metrices  [ 7.04658365  6.89385271]\n",
      "dist  4.95336065041e-05\n",
      "epoch  159  Amari metric:  0.149356694526\n",
      "loss  [-7029.19580078 -6207.13476562]\n",
      "metrices  [ 7.04648304  6.89394903]\n",
      "dist  3.11076708031e-05\n",
      "epoch  160  Amari metric:  0.149340958746\n",
      "loss  [-7029.46923828 -6207.79296875]\n",
      "metrices  [ 7.04646969  6.89414549]\n",
      "dist  1.53918957035e-05\n",
      "epoch  161  Amari metric:  0.149319654282\n",
      "loss  [-7029.60205078 -6207.85253906]\n",
      "metrices  [ 7.04644156  6.89424324]\n",
      "dist  2.08389962411e-05\n",
      "epoch  162  Amari metric:  0.149305392533\n",
      "loss  [-7029.80322266 -6207.82568359]\n",
      "metrices  [ 7.0464201   6.89430904]\n",
      "dist  1.39502250673e-05\n",
      "epoch  163  Amari metric:  0.149286298826\n",
      "loss  [-7029.875      -6207.65869141]\n",
      "metrices  [ 7.04638624  6.89436531]\n",
      "dist  1.86767278456e-05\n",
      "epoch  164  Amari metric:  0.149266195739\n",
      "loss  [-7029.95800781 -6207.52685547]\n",
      "metrices  [ 7.04635048  6.89443159]\n",
      "dist  1.96641776562e-05\n",
      "epoch  165  Amari metric:  0.149133184271\n",
      "loss  [-7025.94189453 -6207.56933594]\n",
      "metrices  [ 7.04610538  6.89450407]\n",
      "dist  0.00013011034215\n",
      "epoch  166  Amari metric:  0.149184714412\n",
      "loss  [-7026.32910156 -6207.41455078]\n",
      "metrices  [ 7.04611588  6.89462328]\n",
      "dist  5.04068105371e-05\n",
      "epoch  167  Amari metric:  0.149212947698\n",
      "loss  [-7026.18701172 -6206.70703125]\n",
      "metrices  [ 7.04607201  6.89454365]\n",
      "dist  2.76174939136e-05\n",
      "epoch  168  Amari metric:  0.149256005138\n",
      "loss  [-7026.33691406 -6206.2890625 ]\n",
      "metrices  [ 7.04604959  6.89453125]\n",
      "dist  4.21178829784e-05\n",
      "epoch  169  Amari metric:  0.149293807871\n",
      "loss  [-7026.04394531 -6207.6640625 ]\n",
      "metrices  [ 7.04599524  6.89478874]\n",
      "dist  3.6977402432e-05\n",
      "epoch  170  Amari metric:  0.149448513447\n",
      "loss  [-7029.99804688 -6207.48339844]\n",
      "metrices  [ 7.04616976  6.89485741]\n",
      "dist  0.000151323704976\n",
      "epoch  171  Amari metric:  0.149419191837\n",
      "loss  [-7029.33105469 -6207.67578125]\n",
      "metrices  [ 7.04609299  6.89499044]\n",
      "dist  2.86801133265e-05\n",
      "epoch  172  Amari metric:  0.149396937092\n",
      "loss  [-7029.12207031 -6207.40722656]\n",
      "metrices  [ 7.04599714  6.89505863]\n",
      "dist  2.1768020267e-05\n",
      "epoch  173  Amari metric:  0.149395500396\n",
      "loss  [-7029.30078125 -6207.45507812]\n",
      "metrices  [ 7.04597378  6.89515638]\n",
      "dist  1.40527937242e-06\n",
      "epoch  174  Amari metric:  0.149393350601\n",
      "loss  [-7029.31591797 -6207.47949219]\n",
      "metrices  [ 7.04594088  6.89524364]\n",
      "dist  2.1027862851e-06\n",
      "epoch  175  Amari metric:  0.149395191667\n",
      "loss  [-7029.33789062 -6207.50195312]\n",
      "metrices  [ 7.04590559  6.89531422]\n",
      "dist  1.80080845857e-06\n",
      "epoch  176  Amari metric:  0.149399523435\n",
      "loss  [-7029.32617188 -6207.52246094]\n",
      "metrices  [ 7.04586935  6.8953743 ]\n",
      "dist  4.23704292296e-06\n",
      "epoch  177  Amari metric:  0.149406900215\n",
      "loss  [-7029.29150391 -6207.54101562]\n",
      "metrices  [ 7.04583073  6.89543152]\n",
      "dist  7.21545552462e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  178  Amari metric:  0.149416487134\n",
      "loss  [-7029.24511719 -6207.54345703]\n",
      "metrices  [ 7.04579306  6.89548731]\n",
      "dist  9.37723771011e-06\n",
      "epoch  179  Amari metric:  0.149434248753\n",
      "loss  [-7029.16796875 -6207.56005859]\n",
      "metrices  [ 7.04575205  6.89554024]\n",
      "dist  1.7373073232e-05\n",
      "epoch  180  Amari metric:  0.149465732872\n",
      "loss  [-7029.44970703 -6207.57324219]\n",
      "metrices  [ 7.04578304  6.89558554]\n",
      "dist  3.07951655889e-05\n",
      "epoch  181  Amari metric:  0.149488811088\n",
      "loss  [-7029.17041016 -6208.15136719]\n",
      "metrices  [ 7.0457201   6.89570713]\n",
      "dist  2.2573025515e-05\n",
      "epoch  182  Amari metric:  0.149516772948\n",
      "loss  [-7029.00585938 -6208.07861328]\n",
      "metrices  [ 7.04566622  6.89573812]\n",
      "dist  2.73495608796e-05\n",
      "epoch  183  Amari metric:  0.149551794062\n",
      "loss  [-7028.84082031 -6208.14257812]\n",
      "metrices  [ 7.04561567  6.89578009]\n",
      "dist  3.42539182858e-05\n",
      "epoch  184  Amari metric:  0.149616537695\n",
      "loss  [-7028.94873047 -6208.00390625]\n",
      "metrices  [ 7.0456028   6.89578342]\n",
      "dist  6.33243921724e-05\n",
      "epoch  185  Amari metric:  0.149662726982\n",
      "loss  [-7028.45263672 -6208.31054688]\n",
      "metrices  [ 7.04552746  6.89585352]\n",
      "dist  4.51760421269e-05\n",
      "epoch  186  Amari metric:  0.149733657888\n",
      "loss  [-7028.59472656 -6208.00195312]\n",
      "metrices  [ 7.04549646  6.8958559 ]\n",
      "dist  6.93737209347e-05\n",
      "epoch  187  Amari metric:  0.149844577377\n",
      "loss  [-7029.71289062 -6207.70458984]\n",
      "metrices  [ 7.04560471  6.89587164]\n",
      "dist  0.000108481526001\n",
      "epoch  188  Amari metric:  0.149914166243\n",
      "loss  [-7029.46777344 -6207.79101562]\n",
      "metrices  [ 7.04555655  6.89590216]\n",
      "dist  6.80575330421e-05\n",
      "epoch  189  Amari metric:  0.150011554126\n",
      "loss  [-7029.76367188 -6209.22509766]\n",
      "metrices  [ 7.04554605  6.89613724]\n",
      "dist  9.52424909508e-05\n",
      "epoch  190  Amari metric:  0.150151663028\n",
      "loss  [-7030.95410156 -6207.60546875]\n",
      "metrices  [ 7.04566908  6.89583302]\n",
      "dist  0.000137017622994\n",
      "epoch  191  Amari metric:  0.150227647912\n",
      "loss  [-7030.09667969 -6208.12841797]\n",
      "metrices  [ 7.04557705  6.89592695]\n",
      "dist  7.43060420381e-05\n",
      "epoch  192  Amari metric:  0.150352710187\n",
      "loss  [-7030.58398438 -6208.22802734]\n",
      "metrices  [ 7.04573059  6.89596891]\n",
      "dist  0.000122295488089\n",
      "epoch  193  Amari metric:  0.150462522088\n",
      "loss  [-7030.18017578 -6210.57617188]\n",
      "metrices  [ 7.04570627  6.89642382]\n",
      "dist  0.000107378796807\n",
      "epoch  194  Amari metric:  0.150533762703\n",
      "loss  [-7028.48828125 -6211.49707031]\n",
      "metrices  [ 7.04547596  6.89660072]\n",
      "dist  6.96602819228e-05\n",
      "epoch  195  Amari metric:  0.150691903464\n",
      "loss  [-7028.40722656 -6211.72070312]\n",
      "metrices  [ 7.04543114  6.89667416]\n",
      "dist  0.000154627499689\n",
      "epoch  196  Amari metric:  0.150893650709\n",
      "loss  [-7029.44335938 -6211.94628906]\n",
      "metrices  [ 7.04544544  6.89677048]\n",
      "dist  0.000197254768968\n",
      "epoch  197  Amari metric:  0.151051874238\n",
      "loss  [-7029.64550781 -6209.84912109]\n",
      "metrices  [ 7.04547119  6.89640617]\n",
      "dist  0.000154692021788\n",
      "epoch  198  Amari metric:  0.151277133225\n",
      "loss  [-7033.9765625  -6209.71142578]\n",
      "metrices  [ 7.04570675  6.89640665]\n",
      "dist  0.000220218804036\n",
      "epoch  199  Amari metric:  0.151285613724\n",
      "loss  [-7032.86425781 -6210.15869141]\n",
      "metrices  [ 7.04560566  6.89650774]\n",
      "dist  8.29046167494e-06\n",
      "epoch  200  Amari metric:  0.151380547279\n",
      "loss  [-7034.55664062 -6210.15136719]\n",
      "metrices  [ 7.04566526  6.8965373 ]\n",
      "dist  9.28047864455e-05\n",
      "epoch  201  Amari metric:  0.151390923615\n",
      "loss  [-7035.23486328 -6210.51611328]\n",
      "metrices  [ 7.04572773  6.89661026]\n",
      "dist  1.01435016469e-05\n",
      "epoch  202  Amari metric:  0.151409264456\n",
      "loss  [-7035.14794922 -6210.51464844]\n",
      "metrices  [ 7.04568863  6.89662313]\n",
      "dist  1.79292150562e-05\n",
      "epoch  203  Amari metric:  0.151440366463\n",
      "loss  [-7034.94580078 -6211.35351562]\n",
      "metrices  [ 7.04562998  6.89674711]\n",
      "dist  3.04037572576e-05\n",
      "epoch  204  Amari metric:  0.151476547105\n",
      "loss  [-7034.76074219 -6211.66748047]\n",
      "metrices  [ 7.04558611  6.89680386]\n",
      "dist  3.53680240157e-05\n",
      "epoch  205  Amari metric:  0.151566596858\n",
      "loss  [-7035.07861328 -6211.60595703]\n",
      "metrices  [ 7.04557323  6.89681864]\n",
      "dist  8.80255898106e-05\n",
      "epoch  206  Amari metric:  0.151698039749\n",
      "loss  [-7040.29345703 -6211.72460938]\n",
      "metrices  [ 7.04581738  6.89685059]\n",
      "dist  0.000128484066865\n",
      "epoch  207  Amari metric:  0.15155862947\n",
      "loss  [-7039.23339844 -6211.56738281]\n",
      "metrices  [ 7.04567957  6.89685917]\n",
      "dist  0.000136272267579\n",
      "epoch  208  Amari metric:  0.151491350166\n",
      "loss  [-7040.37158203 -6211.76513672]\n",
      "metrices  [ 7.0457387   6.89687395]\n",
      "dist  6.57669144519e-05\n",
      "epoch  209  Amari metric:  0.151374628847\n",
      "loss  [-7034.93261719 -6211.71875   ]\n",
      "metrices  [ 7.04539108  6.89686632]\n",
      "dist  0.000114100615197\n",
      "epoch  210  Amari metric:  0.151523584123\n",
      "loss  [-7035.32128906 -6210.68457031]\n",
      "metrices  [ 7.04542112  6.89674091]\n",
      "dist  0.000145610140541\n",
      "epoch  211  Amari metric:  0.151694374386\n",
      "loss  [-7040.20068359 -6211.75683594]\n",
      "metrices  [ 7.04564142  6.89688253]\n",
      "dist  0.000166946871171\n",
      "epoch  212  Amari metric:  0.151629009541\n",
      "loss  [-7039.30615234 -6211.66015625]\n",
      "metrices  [ 7.04551554  6.89690924]\n",
      "dist  6.38929033934e-05\n",
      "epoch  213  Amari metric:  0.15158702872\n",
      "loss  [-7039.80908203 -6211.85351562]\n",
      "metrices  [ 7.0455246   6.89693546]\n",
      "dist  4.10361142973e-05\n",
      "epoch  214  Amari metric:  0.151567048186\n",
      "loss  [-7040.15332031 -6211.93798828]\n",
      "metrices  [ 7.04551458  6.89695358]\n",
      "dist  1.95310855311e-05\n",
      "epoch  215  Amari metric:  0.151560890245\n",
      "loss  [-7040.33203125 -6211.89013672]\n",
      "metrices  [ 7.04549122  6.89694834]\n",
      "dist  6.01944491319e-06\n",
      "epoch  216  Amari metric:  0.151551733037\n",
      "loss  [-7040.390625   -6211.91162109]\n",
      "metrices  [ 7.04546213  6.89695883]\n",
      "dist  8.95127751654e-06\n",
      "epoch  217  Amari metric:  0.151560925708\n",
      "loss  [-7040.4609375  -6211.93457031]\n",
      "metrices  [ 7.04543352  6.89697456]\n",
      "dist  8.98594279652e-06\n",
      "epoch  218  Amari metric:  0.151568678098\n",
      "loss  [-7040.39941406 -6211.94921875]\n",
      "metrices  [ 7.0453968   6.89699125]\n",
      "dist  7.57803274221e-06\n",
      "epoch  219  Amari metric:  0.151588349264\n",
      "loss  [-7040.33691406 -6211.96582031]\n",
      "metrices  [ 7.04536009  6.89702034]\n",
      "dist  1.92286679912e-05\n",
      "epoch  220  Amari metric:  0.151611215698\n",
      "loss  [-7040.16943359 -6212.05322266]\n",
      "metrices  [ 7.04531431  6.89706516]\n",
      "dist  2.23519178648e-05\n",
      "epoch  221  Amari metric:  0.151646285677\n",
      "loss  [-7040.00292969 -6211.94287109]\n",
      "metrices  [ 7.04526949  6.89706945]\n",
      "dist  3.42805780909e-05\n",
      "epoch  222  Amari metric:  0.151689480373\n",
      "loss  [-7039.69482422 -6211.98339844]\n",
      "metrices  [ 7.04521179  6.897089  ]\n",
      "dist  4.22219241454e-05\n",
      "epoch  223  Amari metric:  0.151754538335\n",
      "loss  [-7039.40283203 -6211.87109375]\n",
      "metrices  [ 7.04515266  6.89709997]\n",
      "dist  6.35917947389e-05\n",
      "epoch  224  Amari metric:  0.151776601139\n",
      "loss  [-7038.81835938 -6211.89990234]\n",
      "metrices  [ 7.04508448  6.89712667]\n",
      "dist  2.15653110955e-05\n",
      "epoch  225  Amari metric:  0.151836379749\n",
      "loss  [-7038.69970703 -6211.72607422]\n",
      "metrices  [ 7.04504728  6.89712572]\n",
      "dist  5.84299573143e-05\n",
      "epoch  226  Amari metric:  0.151875081008\n",
      "loss  [-7038.25878906 -6211.90234375]\n",
      "metrices  [ 7.04498625  6.89716816]\n",
      "dist  3.78275751802e-05\n",
      "epoch  227  Amari metric:  0.151921163926\n",
      "loss  [-7037.90527344 -6211.69433594]\n",
      "metrices  [ 7.04492664  6.89714432]\n",
      "dist  4.50420252855e-05\n",
      "epoch  228  Amari metric:  0.152013833964\n",
      "loss  [-7038.05371094 -6212.14160156]\n",
      "metrices  [ 7.04490232  6.89723539]\n",
      "dist  9.05750010263e-05\n",
      "epoch  229  Amari metric:  0.152080758855\n",
      "loss  [-7037.78320312 -6212.86523438]\n",
      "metrices  [ 7.04487038  6.89735699]\n",
      "dist  6.54103373545e-05\n",
      "epoch  230  Amari metric:  0.152152484516\n",
      "loss  [-7038.77148438 -6212.94726562]\n",
      "metrices  [ 7.04500484  6.89738607]\n",
      "dist  7.01010190161e-05\n",
      "epoch  231  Amari metric:  0.152208308469\n",
      "loss  [-7038.60253906 -6212.95605469]\n",
      "metrices  [ 7.04496193  6.89739752]\n",
      "dist  5.45584627223e-05\n",
      "epoch  232  Amari metric:  0.152252975361\n",
      "loss  [-7038.33642578 -6212.91308594]\n",
      "metrices  [ 7.04493332  6.89738417]\n",
      "dist  4.36536723143e-05\n",
      "epoch  233  Amari metric:  0.152299127775\n",
      "loss  [-7037.95068359 -6212.96826172]\n",
      "metrices  [ 7.04487419  6.89740133]\n",
      "dist  4.51048888332e-05\n",
      "epoch  234  Amari metric:  0.152364909196\n",
      "loss  [-7038.03759766 -6214.09863281]\n",
      "metrices  [ 7.04487705  6.89757204]\n",
      "dist  6.42873026593e-05\n",
      "epoch  235  Amari metric:  0.152408424488\n",
      "loss  [-7037.58251953 -6214.3203125 ]\n",
      "metrices  [ 7.04482412  6.89761209]\n",
      "dist  4.25262213781e-05\n",
      "epoch  236  Amari metric:  0.152466856307\n",
      "loss  [-7037.484375   -6214.66601562]\n",
      "metrices  [ 7.04481125  6.89768648]\n",
      "dist  5.71028404888e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  237  Amari metric:  0.152555399606\n",
      "loss  [-7037.85302734 -6214.49267578]\n",
      "metrices  [ 7.04485035  6.89765358]\n",
      "dist  8.65275678397e-05\n",
      "epoch  238  Amari metric:  0.152615555675\n",
      "loss  [-7037.06787109 -6214.8359375 ]\n",
      "metrices  [ 7.0447588   6.89771795]\n",
      "dist  5.87852854681e-05\n",
      "epoch  239  Amari metric:  0.152672178558\n",
      "loss  [-7036.88525391 -6214.77392578]\n",
      "metrices  [ 7.04472446  6.89770222]\n",
      "dist  5.53316465974e-05\n",
      "epoch  240  Amari metric:  0.15272437922\n",
      "loss  [-7040.32373047 -6215.11621094]\n",
      "metrices  [ 7.04490137  6.89776325]\n",
      "dist  5.10094443436e-05\n",
      "epoch  241  Amari metric:  0.152634573251\n",
      "loss  [-7040.11962891 -6215.30029297]\n",
      "metrices  [ 7.0448637   6.89780951]\n",
      "dist  8.77570900217e-05\n",
      "epoch  242  Amari metric:  0.152600890192\n",
      "loss  [-7040.58447266 -6214.8359375 ]\n",
      "metrices  [ 7.04482985  6.89772367]\n",
      "dist  3.29152025744e-05\n",
      "epoch  243  Amari metric:  0.152573804084\n",
      "loss  [-7037.03076172 -6214.88037109]\n",
      "metrices  [ 7.04458952  6.89772654]\n",
      "dist  2.64688786893e-05\n",
      "epoch  244  Amari metric:  0.152727102605\n",
      "loss  [-7037.28222656 -6215.00097656]\n",
      "metrices  [ 7.04458857  6.89776659]\n",
      "dist  0.000149802387604\n",
      "epoch  245  Amari metric:  0.152786943068\n",
      "loss  [-7040.11425781 -6215.40136719]\n",
      "metrices  [ 7.04474926  6.89783382]\n",
      "dist  5.84738798226e-05\n",
      "epoch  246  Amari metric:  0.152725193047\n",
      "loss  [-7039.62695312 -6214.96630859]\n",
      "metrices  [ 7.04466915  6.89775324]\n",
      "dist  6.0339846861e-05\n",
      "epoch  247  Amari metric:  0.152713981596\n",
      "loss  [-7040.13964844 -6215.45605469]\n",
      "metrices  [ 7.04467583  6.8978467 ]\n",
      "dist  1.09555357377e-05\n",
      "epoch  248  Amari metric:  0.152698117105\n",
      "loss  [-7040.24316406 -6215.53369141]\n",
      "metrices  [ 7.04465008  6.89785433]\n",
      "dist  1.5502427225e-05\n",
      "epoch  249  Amari metric:  0.152692891072\n",
      "loss  [-7040.14111328 -6215.56835938]\n",
      "metrices  [ 7.04458666  6.89786053]\n",
      "dist  5.10677984722e-06\n",
      "epoch  250  Amari metric:  0.15270207735\n",
      "loss  [-7040.19140625 -6215.59667969]\n",
      "metrices  [ 7.044559    6.89786911]\n",
      "dist  8.97664968047e-06\n",
      "epoch  251  Amari metric:  0.152715424746\n",
      "loss  [-7040.11523438 -6215.62158203]\n",
      "metrices  [ 7.04452181  6.89787197]\n",
      "dist  1.30427673843e-05\n",
      "epoch  252  Amari metric:  0.152738535321\n",
      "loss  [-7040.24755859 -6215.64453125]\n",
      "metrices  [ 7.04452658  6.89788103]\n",
      "dist  2.25829987988e-05\n",
      "epoch  253  Amari metric:  0.152761151448\n",
      "loss  [-7040.17578125 -6215.61523438]\n",
      "metrices  [ 7.04449797  6.89788485]\n",
      "dist  2.20996876052e-05\n",
      "epoch  254  Amari metric:  0.152780192463\n",
      "loss  [-7039.97851562 -6215.51318359]\n",
      "metrices  [ 7.04445601  6.89787006]\n",
      "dist  1.86060973333e-05\n",
      "epoch  255  Amari metric:  0.152805219614\n",
      "loss  [-7039.72705078 -6215.15429688]\n",
      "metrices  [ 7.04439878  6.89779615]\n",
      "dist  2.44553427822e-05\n",
      "epoch  256  Amari metric:  0.15283717264\n",
      "loss  [-7039.51220703 -6215.40478516]\n",
      "metrices  [ 7.04434967  6.89783287]\n",
      "dist  3.12227135535e-05\n",
      "epoch  257  Amari metric:  0.152885860736\n",
      "loss  [-7039.51318359 -6215.12255859]\n",
      "metrices  [ 7.04433155  6.89781094]\n",
      "dist  4.75747171693e-05\n",
      "epoch  258  Amari metric:  0.152934076407\n",
      "loss  [-7039.27099609 -6214.68847656]\n",
      "metrices  [ 7.04429436  6.89776087]\n",
      "dist  4.71124131685e-05\n",
      "epoch  259  Amari metric:  0.152986369907\n",
      "loss  [-7038.88085938 -6214.75830078]\n",
      "metrices  [ 7.04423285  6.89776516]\n",
      "dist  5.10961681419e-05\n",
      "epoch  260  Amari metric:  0.153049488226\n",
      "loss  [-7038.54980469 -6215.08300781]\n",
      "metrices  [ 7.04418135  6.8978014 ]\n",
      "dist  6.16720744862e-05\n",
      "epoch  261  Amari metric:  0.153100698086\n",
      "loss  [-7037.98388672 -6214.90673828]\n",
      "metrices  [ 7.04410362  6.897789  ]\n",
      "dist  5.00356219311e-05\n",
      "epoch  262  Amari metric:  0.153173513494\n",
      "loss  [-7037.734375   -6214.92138672]\n",
      "metrices  [ 7.04406118  6.89781046]\n",
      "dist  7.11444378334e-05\n",
      "epoch  263  Amari metric:  0.153243298342\n",
      "loss  [-7037.40283203 -6215.49853516]\n",
      "metrices  [ 7.04401875  6.89789343]\n",
      "dist  6.81819689823e-05\n",
      "epoch  264  Amari metric:  0.153291491372\n",
      "loss  [-7036.76025391 -6215.0859375 ]\n",
      "metrices  [ 7.04393244  6.89785004]\n",
      "dist  4.7085259351e-05\n",
      "epoch  265  Amari metric:  0.153359499864\n",
      "loss  [-7036.41503906 -6214.76757812]\n",
      "metrices  [ 7.04387712  6.89779902]\n",
      "dist  6.64440849172e-05\n",
      "epoch  266  Amari metric:  0.153438763557\n",
      "loss  [-7036.00927734 -6214.72119141]\n",
      "metrices  [ 7.04382896  6.89778137]\n",
      "dist  7.7438674472e-05\n",
      "epoch  267  Amari metric:  0.15352969744\n",
      "loss  [-7036.32617188 -6214.45947266]\n",
      "metrices  [ 7.0438447   6.89776373]\n",
      "dist  8.8837896296e-05\n",
      "epoch  268  Amari metric:  0.153623157529\n",
      "loss  [-7036.43017578 -6214.58300781]\n",
      "metrices  [ 7.0438261   6.89778709]\n",
      "dist  9.13033514505e-05\n",
      "epoch  269  Amari metric:  0.153719370312\n",
      "loss  [-7037.17724609 -6214.88525391]\n",
      "metrices  [ 7.04387283  6.89784098]\n",
      "dist  9.3989849812e-05\n",
      "epoch  270  Amari metric:  0.153789865357\n",
      "loss  [-7038.17089844 -6214.82666016]\n",
      "metrices  [ 7.04406834  6.89785433]\n",
      "dist  6.88645802551e-05\n",
      "epoch  271  Amari metric:  0.153789867978\n",
      "loss  [-7038.33300781 -6214.95263672]\n",
      "metrices  [ 7.04406977  6.8978653 ]\n",
      "dist  2.55968446439e-09\n"
     ]
    }
   ],
   "source": [
    "#M=200 lbd=0.05还行\n",
    "#神经网络需要调整参数，不是很好的问题，不值得太花费时间.\n",
    "maxiters =2000\n",
    "epochs =200\n",
    "batch_size =1024\n",
    "m  =2\n",
    "M  =200*8\n",
    "W =np.random.normal(size=(m,m))\n",
    "W =orth(W)\n",
    "W_last =np.random.normal(size=(m,m))\n",
    "print('Amari metric ',Amari_metric(target,W))\n",
    "models =[]\n",
    "inputs =[]\n",
    "outputs =[]\n",
    "loss     =np.zeros((maxiters,m),dtype=float)\n",
    "metrices =np.zeros((maxiters,m),dtype=float)\n",
    "y_pred =np.zeros((1024,m),dtype=float)\n",
    "tol =1e-7\n",
    "for i in range(m):\n",
    "    input_tensor =Input(shape=(1,),dtype='float32')\n",
    "    x =layers.Dense(M,activation='sigmoid',kernel_initializer='random_uniform',\n",
    "                bias_initializer='zeros')(input_tensor)\n",
    "    #x =layers.Dense(50,activation='sigmoid',kernel_initializer='random_uniform',\n",
    "    #            bias_initializer='zeros',kernel_regularizer=regularizers.l1(1))(x)\n",
    "    output_tensor =layers.Dense(1,activation=\"linear\",kernel_initializer='random_uniform',\n",
    "                bias_initializer='zeros',kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    model =Model(input_tensor,output_tensor)\n",
    "    model.compile(optimizer='rmsprop',loss=mdi_loss4,metrics=[negentropy])\n",
    "    models.append(model)\n",
    "    inputs.append(input_tensor)\n",
    "    outputs.append(output_tensor)\n",
    "\n",
    "for i in range(maxiters):\n",
    "    #X_train =(W@X.T).T\n",
    "    #y_train =gauss_standard(X_train)\n",
    "    Xs =(W@X.T).T\n",
    "    #[X_train,y_train] =group(X_train)\n",
    "    print('dist ',Amari_metric(W_last,W))\n",
    "    if(Amari_metric(W_last,W)<tol):\n",
    "        break\n",
    "    W_last =W.copy()\n",
    "    for j in range(m):\n",
    "        [X_train,y_train] =group(Xs[:,j],B=500)\n",
    "        y_train =y_train/gauss_standard(X_train)\n",
    "        for k in range(epochs):\n",
    "            [loss[i,j],metrices[i,j]] =models[j].train_on_batch(x=X_train,y=y_train)\n",
    "        #models[j].fit(X_train[:,j][:,np.newaxis],y_train[:,j][:,np.newaxis],epochs=100,batch_size=1024,verbose=0)\n",
    "        grad  =K.gradients(models[j].output,[models[j].input])[0]\n",
    "        grad2 =K.gradients(grad,[models[j].input])[0]\n",
    "        grads =K.function([models[j].input],[grad,grad2])\n",
    "        #print('grad ',grad)\n",
    "        #print('grad2 ',grad2)\n",
    "        #K.update(models[j].input,X_train[:,j])\n",
    "        [grad_val,grad2_val] =grads([Xs[:,j][:,np.newaxis]])\n",
    "        \n",
    "        #print('norm ',np.linalg.norm(grad_val))\n",
    "        #print('grad_val ',grad_val)\n",
    "        W[j,:] =np.mean(X*grad_val,axis=0)-np.mean(grad2_val)*W[j,:]\n",
    "        if(j>0):\n",
    "            W[j,:] =W[j,:]-(np.sum(W[j,:]*W[j-1,:]))*W[j-1,:]\n",
    "        W[j,:] =W[j,:]/np.linalg.norm(W[j,:])\n",
    "    #print('before W ',W)\n",
    "    #W =orth(W)\n",
    "    #if(i<10):\n",
    "    #    print('W_last ',W_last)\n",
    "    #    print('W ',W )\n",
    "    print('epoch ',i,' Amari metric: ',Amari_metric(target,W))\n",
    "    print('loss ',loss[i,:])\n",
    "    print('metrices ',metrices[i,:])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group(Xs[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0  begin\n"
     ]
    }
   ],
   "source": [
    "[W,metrics]=neuralICA(X,W0=W0,M=1024,maxiters=20,epochs=200,optimizer='rmsprop',tol=1e-7,activation='sigmoid',lbd=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 100, 1024)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition  1.37894287867\n",
      "condition  1.253542588\n",
      "condition  1.55775619345\n",
      "condition  1.45484727925\n",
      "condition  1.00702291659\n",
      "condition  1.0038730418\n",
      "condition  1.21191847819\n",
      "condition  1.0454329456\n",
      "condition  1.07785104355\n",
      "condition  1.24011916343\n",
      "condition  1.28180860331\n",
      "condition  1.03850530372\n",
      "condition  1.06004238406\n",
      "condition  1.09420849669\n",
      "condition  1.22337499737\n",
      "condition  1.25175975608\n",
      "condition  1.14557891996\n",
      "condition  1.64536132015\n",
      "condition  1.06905215078\n",
      "condition  1.07057263912\n",
      "condition  1.5233731116\n",
      "condition  1.29257158662\n",
      "condition  1.26812319581\n",
      "condition  1.11100397832\n",
      "condition  1.44701599948\n",
      "condition  1.42649475442\n",
      "condition  1.20707971668\n",
      "condition  1.34022959757\n",
      "condition  1.42477909621\n",
      "condition  1.36521509776\n",
      "condition  1.03017156495\n",
      "condition  1.53077594929\n",
      "condition  1.05494480051\n",
      "condition  1.08987274595\n",
      "condition  1.15420903715\n",
      "condition  1.40239418926\n",
      "condition  1.03946812433\n",
      "condition  1.52994770336\n",
      "condition  1.2295761528\n",
      "condition  1.10868435732\n",
      "condition  1.40274415617\n",
      "condition  1.06388535603\n",
      "condition  1.01270304975\n",
      "condition  1.33831702414\n",
      "condition  1.04897237865\n",
      "condition  1.03160101348\n",
      "condition  1.83977653225\n",
      "condition  1.30813632443\n",
      "condition  1.3598586148\n",
      "condition  1.12261571974\n",
      "condition  1.17682300981\n",
      "condition  1.15529634994\n",
      "condition  1.65095651177\n",
      "condition  1.1651765743\n",
      "condition  1.05013145432\n",
      "condition  1.44765275944\n",
      "condition  1.07954542969\n",
      "condition  1.39958066524\n",
      "condition  1.51923323063\n",
      "condition  1.30543202562\n",
      "condition  1.09020163176\n",
      "condition  1.02460517576\n",
      "condition  1.65707480441\n",
      "condition  1.41487767164\n",
      "condition  1.08753413851\n",
      "condition  1.32962892055\n",
      "condition  1.25256785667\n",
      "condition  1.00377611303\n",
      "condition  1.48640884824\n",
      "condition  1.04498289031\n",
      "condition  1.0682364075\n",
      "condition  1.24726215245\n",
      "condition  1.22143465874\n",
      "condition  1.114449043\n",
      "condition  1.0725174083\n",
      "condition  1.64102598093\n",
      "condition  1.48323136503\n",
      "condition  1.45593011514\n",
      "condition  1.22127040813\n",
      "condition  1.1195078722\n",
      "condition  1.38332140197\n",
      "condition  1.51980552625\n",
      "condition  1.27337937084\n",
      "condition  1.3132978778\n",
      "condition  1.09293909989\n",
      "condition  1.70385039976\n",
      "condition  1.62482106003\n",
      "condition  1.00347528584\n",
      "condition  1.35502775037\n",
      "condition  1.00802293489\n",
      "condition  1.1018427544\n",
      "condition  1.50713264494\n",
      "condition  1.40680291654\n",
      "condition  1.43786256206\n",
      "condition  1.44988358336\n",
      "condition  1.00268037496\n",
      "condition  1.62319203737\n",
      "condition  1.7423946008\n",
      "condition  1.79218455188\n",
      "condition  1.02861103711\n",
      "condition  1.06776786753\n",
      "condition  1.30254350232\n",
      "condition  1.08983974074\n",
      "condition  1.23737058157\n",
      "condition  1.0294663637\n",
      "condition  1.82359747517\n",
      "condition  1.48572889923\n",
      "condition  1.23723847242\n",
      "condition  1.0576092218\n",
      "condition  1.46927307553\n",
      "condition  1.14514858453\n",
      "condition  1.30207994029\n",
      "condition  1.05112918142\n"
     ]
    }
   ],
   "source": [
    "dim2data =np.zeros((18,30,2,1024),dtype=float)\n",
    "dim2target =np.zeros((18,30,2,2),dtype=float)\n",
    "dim2W0 =np.zeros((18,30,2,2),dtype=float)\n",
    "dim2W  =np.zeros((18,30,2,2),dtype=float)\n",
    "amaris =np.zeros((18,30),dtype=float)\n",
    "maxiters =20\n",
    "epochs =20\n",
    "M=1024\n",
    "for ii in range(18):\n",
    "    for jj in range(30):\n",
    "        m  =2\n",
    "        S  =data[ii,[jj,jj+30],:].T\n",
    "        A0 =mixmat(2)\n",
    "        X  =(A0@S.T).T\n",
    "        X  =scale(X,center=True,scale=False)\n",
    "        [P,X] =whiten(X)\n",
    "        target =np.linalg.inv(P@A0)\n",
    "        W0 =np.random.normal(size=(2,2))\n",
    "        W0 =orth(W0)\n",
    "        \n",
    "        W =W0.copy()\n",
    "        W_last =np.random.normal(size=(m,m))\n",
    "\n",
    "        models =[]\n",
    "        inputs =[]\n",
    "        outputs =[]\n",
    "        loss     =np.zeros((maxiters,m),dtype=float)\n",
    "        metrices =np.zeros((maxiters,m),dtype=float)\n",
    "        y_pred =np.zeros((1024,m),dtype=float)\n",
    "        tol =1e-7\n",
    "        for i in range(m):\n",
    "            input_tensor =Input(shape=(1,),dtype='float32')\n",
    "            x =layers.Dense(M,activation='sigmoid',kernel_initializer='random_uniform',\n",
    "                bias_initializer='zeros')(input_tensor)\n",
    "            output_tensor =layers.Dense(1,activation=\"linear\",kernel_initializer='random_uniform',\n",
    "                bias_initializer='zeros',kernel_regularizer=regularizers.l2(0.05))(x)\n",
    "            model =Model(input_tensor,output_tensor)\n",
    "            model.compile(optimizer='rmsprop',loss=mdi_loss2,metrics=[negentropy])\n",
    "            models.append(model)\n",
    "            inputs.append(input_tensor)\n",
    "            outputs.append(output_tensor)\n",
    "        for i in range(maxiters):\n",
    "            \n",
    "            X_train =(W@X.T).T\n",
    "            []\n",
    "            if(Amari_metric(W_last,W)<tol):\n",
    "                break\n",
    "            W_last =W.copy()\n",
    "            for j in range(m):\n",
    "                for k in range(epochs):\n",
    "                    [loss[i,j],metrices[i,j]] =models[j].train_on_batch(x=X_train[:,j],y=y_train[:,j])\n",
    "                grad  =K.gradients(models[j].output,[models[j].input])[0]\n",
    "                grad2 =K.gradients(grad,[models[j].input])[0]\n",
    "                grads =K.function([models[j].input],[grad,grad2])\n",
    "                [grad_val,grad2_val] =grads([X_train[:,j][:,np.newaxis]])\n",
    "                W[j,:] =np.mean(X*grad_val,axis=0)-np.mean(grad2_val)*W[j,:]\n",
    "\n",
    "            W =orth(W)\n",
    "            #print('epoch ',i,' Amari metric: ',Amari_metric(target,W))\n",
    "            #print('loss ',loss[i,:])\n",
    "            #print('metrices ',metrices[i,:])\n",
    "        \n",
    "    dim2data[ii,jj,:,:]=S.T.copy()\n",
    "    dim2target[ii,jj,:,:] =target.copy()\n",
    "    dim2W0[ii,jj,:,:]=W0.copy()\n",
    "    dim2W[ii,jj,:,:] =W.copy()\n",
    "    amaris[ii,jj] =Amari_metric(target,W)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amari metric  0.312182193261\n",
      "dist  0.725816088103\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "No gradient defined for operation 'gradients_818/dense_112/Softplus_grad/SoftplusGrad' (op type: SoftplusGrad)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/py/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m               \u001b[0mgrad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradient_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_gradient_function\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1643\u001b[0m     \u001b[0mop_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1644\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_gradient_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py/lib/python3.6/site-packages/tensorflow/python/framework/registry.py\u001b[0m in \u001b[0;36mlookup\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     92\u001b[0m       raise LookupError(\n\u001b[0;32m---> 93\u001b[0;31m           \"%s registry has no entry for: %s\" % (self._name, name))\n\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m: gradient registry has no entry for: SoftplusGrad",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-ebcf2c81d682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m#models[j].fit(X_train[:,j][:,np.newaxis],y_train[:,j][:,np.newaxis],epochs=100,batch_size=1024,verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mgrad\u001b[0m  \u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mgrad2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m#print('grad ',grad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   2392\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \"\"\"\n\u001b[0;32m-> 2394\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\u001b[0m\n\u001b[1;32m    532\u001b[0m               raise LookupError(\n\u001b[1;32m    533\u001b[0m                   \u001b[0;34m\"No gradient defined for operation '%s' (op type: %s)\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m                   (op.name, op.type))\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloop_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m           \u001b[0mloop_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnterGradWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: No gradient defined for operation 'gradients_818/dense_112/Softplus_grad/SoftplusGrad' (op type: SoftplusGrad)"
     ]
    }
   ],
   "source": [
    "epochs =20\n",
    "batch_size =1024\n",
    "m  =2\n",
    "M  =50\n",
    "W =np.random.normal(size=(m,m))\n",
    "W =orth(W)\n",
    "W_last =np.random.normal(size=(m,m))\n",
    "print('Amari metric ',Amari_metric(target,W))\n",
    "models =[]\n",
    "inputs =[]\n",
    "outputs =[]\n",
    "loss     =np.zeros((epochs,m),dtype=float)\n",
    "metrices =np.zeros((epochs,m),dtype=float)\n",
    "y_pred =np.zeros((1024,m),dtype=float)\n",
    "tol =1e-7\n",
    "for i in range(m):\n",
    "    input_tensor =Input(shape=(1,),dtype='float32')\n",
    "    x =layers.Dense(M,activation='sigmoid',kernel_initializer='random_uniform',\n",
    "                bias_initializer='zeros',kernel_regularizer=regularizers.l2(0.001))(input_tensor)\n",
    "    x =layers.Dense(50,activation='sigmoid',kernel_initializer='random_uniform',\n",
    "                bias_initializer='zeros',kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    output_tensor =layers.Dense(1,activation=\"softplus\",kernel_initializer='random_uniform',\n",
    "                bias_initializer='zeros',kernel_regularizer=regularizers.l2(0.05))(x)\n",
    "    model =Model(input_tensor,output_tensor)\n",
    "    model.compile(optimizer='rmsprop',loss=mdi_loss5,metrics=[negentropy])\n",
    "    models.append(model)\n",
    "    inputs.append(input_tensor)\n",
    "    outputs.append(output_tensor)\n",
    "\n",
    "for i in range(epochs):\n",
    "    #X_train =(W@X.T).T\n",
    "    #y_train =gauss_standard(X_train)\n",
    "    Xs =(W@X.T).T\n",
    "    #[X_train,y_train] =group(X_train)\n",
    "    print('dist ',Amari_metric(W_last,W))\n",
    "    if(Amari_metric(W_last,W)<tol):\n",
    "        break\n",
    "    W_last =W.copy()\n",
    "    for j in range(m):\n",
    "        [X_train,y_train] =group(Xs[:,j],B=500)\n",
    "        \n",
    "        for k in range(400):\n",
    "            [loss[i,j],metrices[i,j]] =models[j].train_on_batch(x=X_train,y=y_train)\n",
    "        #models[j].fit(X_train[:,j][:,np.newaxis],y_train[:,j][:,np.newaxis],epochs=100,batch_size=1024,verbose=0)\n",
    "        grad  =K.gradients(models[j].output,[models[j].input])[0]\n",
    "        grad2 =K.gradients(grad,[models[j].input])[0]\n",
    "        grads =K.function([models[j].input],[grad,grad2,models[j].output])\n",
    "        #print('grad ',grad)\n",
    "        #print('grad2 ',grad2)\n",
    "        #K.update(models[j].input,X_train[:,j])\n",
    "        [grad_val,grad2_val,y_pred] =grads([Xs[:,j][:,np.newaxis]])\n",
    "        g1 =grad_val/y_pred\n",
    "        g2 =(grad2_val*y_pred-grad_val*grad_val)/(y_pred*y_pred)\n",
    "        \n",
    "        #print('norm ',np.linalg.norm(grad_val))\n",
    "        #print('grad_val ',grad_val)\n",
    "        #W[j,:] =W[j,:] -(np.mean(X*g1,axis=0))/np.mean(g2)\n",
    "        W[j,:] =np.mean(X*g1,axis=0)-np.mean(g2)*W[j,:]\n",
    "        #if(j>0):\n",
    "        #    W[j,:] =W[j,:]-(np.sum(W[j,:]*W[j-1,:]))*W[j-1,:]\n",
    "        #W[j,:] =W[j,:]/np.linalg.norm(W[j,:])\n",
    "    #print('before W ',W)\n",
    "    W =orth(W)\n",
    "    #if(i<10):\n",
    "    #    print('W_last ',W_last)\n",
    "    #    print('W ',W )\n",
    "    print('epoch ',i,' Amari metric: ',Amari_metric(target,W))\n",
    "    print('loss ',loss[i,:])\n",
    "    print('metrices ',metrices[i,:])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
